# icobench
[scraper]
# number of threads to be run in parallel. try between 15 to 30
# statistics for ICOBENCH (Intel Core i7 6600U CPU @2.60GHz 2.81GHz), 8 gb ram
#-------------------------------|
# thr_num   |  profiles per sec |
#      10   |                   |
#      15   |                   |
#      20   |                   |
#      40   |                   |
#      60   |                   |
#-------------------------------|
threads = 1

# max number of browsers (should be: browsers <= threads)
browsers = 1

# browser type chrome, firefox or phantomjs
driver = "firefox"

# should be selenium or bs4
# selenium is supporting dynamic pages, but is slower comparing with bs4
scraper_engine = "bs4"

# should be lxml or html5lib
html_parser = "lxml"

# should be file or stream
logging_handler = "stream"

# output format, should be excel or json
output_format = "excel"

# if enabled, pagination will be disabled, and the elements should be extracted from first page only
# this functionality is added for debugging
testing = 20

# max number of items to be extracted. for debugging
max_items_extract = 5

# website url (pagination should exists)
[websites urls]
icobench = "https://icobench.com/icos/platform"


[pagination]
# related to pagination only
# should be bs4 or selenium
pagination_engine = "bs4"

# for selenium
wait_before_pagination = 2
wait_after_pagination = 2


# if "use_selenium" is specified then pagination attribute should be xpath or class
pagination_xpath =
pagination_tag = "a"
pagination_attribute = "class"
pagination_attribute_value = "next"


# html information for extracting listing urls
[listings]
listing_tag = "a"
listing_attribute = "class"
listing_attribute_value = "image"


# html information regarding profile fields
# xpath are being use only when scraper_engine is selenium
[profile item xpath]
ICO_PROFILE =   "//*[@id=\"profile_header\"]/div/div[2]/div[1]/div/div[2]/div[1]"
TEAM =          "//*[@id=\"profile_header\"]/div/div[2]/div[1]/div/div[2]/div[2]"
VISION =        "//*[@id=\"profile_header\"]/div/div[2]/div[1]/div/div[2]/div[3]"
PRODUCT =       "//*[@id=\"profile_header\"]/div/div[2]/div[1]/div/div[2]/div[4]"


[profile item id]


# if scraper engine is bs4 then the patterns below should be used

[bs4 find args]
# write an argument for bs4.find function
#############################################
ICO_PROFILE = "(tag='div', text=re.compile('^\s*\d+\.?\d*\s*ICO\s*Profile\s*$', re.IGNORECASE))"

